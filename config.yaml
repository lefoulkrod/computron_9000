models:
  - name: qwen3
    model: qwen3:30b-a3b-thinking-2507-q8_0
    think: true
    options:
      num_ctx: 73728
  - name: qwen3-coder
    model: hf.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:Q8_0
    options:
      num_ctx: 73728
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      repetition_penalty: 1.05
  - name: coder_architect_qwen
    model: qwen3:30b-a3b-thinking-2507-q8_0
    think: true
    options:
      num_ctx: 73728
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      repetition_penalty: 1.05
  - name: coder_developer_qwen
    model: qwen3:30b-a3b-thinking-2507-q8_0
    think: true
    options:
      num_ctx: 73728
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      repetition_penalty: 1.05
  - name: gpt
    model: gpt-oss:120b
    think: true
    options:
      num_ctx: 128000
  - name: handoff_agent
    model: gpt-oss:120b
    think: false
    options:
      num_ctx: 128000
  - name: coder_architect
    model: gpt-oss:120b
    think: true
    options:
      num_ctx: 128000
      reasoning_effort: high
  - name: coder_developer
    model: gpt-oss:120b
    think: true
    options:
      num_ctx: 128000
      reasoning_effort: high
  - name: vision
    model: qwen2.5vl:32b
    options:
      num_ctx: 62464
    think: false
settings:
  home_dir: /home/larry/.computron_9000
  default_model: gpt
virtual_computer:
  container_name: computron_virtual_computer
  container_user: computron
  home_dir: /home/larry/.computron_9000/container_home
  container_working_dir: /home/computron
  
tools:
  web:
    search_google:
      state_file: ".browser-state.json"
      no_save_state: false
      timeout: 6000
agents:
  web:
    think: false
  file_system:
    think: false

# LLM settings. If LLM_HOST env var is set and non-blank, it overrides this value.
# Otherwise, this YAML value is used as the default.
llm:
  host: http://127.0.0.1:11434

